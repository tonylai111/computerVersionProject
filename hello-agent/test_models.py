# @Version :1.0
# @Author  :TonyLai
# @File    :test_models.py
# @Time    :2025/11/14
# æµ‹è¯•ä¸åŒå…è´¹æ¨¡å‹çš„è„šæœ¬

import os
from dotenv import load_dotenv
from chapter04_react import HelloAgentsLLM

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# ========== å…è´¹æ¨¡å‹é…ç½® ==========
FREE_MODELS_CONFIG = {
    # 1. Groq - æ¨èï¼Œé€Ÿåº¦å¿«ï¼Œå…è´¹é¢åº¦å……è¶³
    "groq": {
        "name": "Groq (Llama 3.1)",
        "model": "llama-3.1-70b-versatile",
        "base_url": "https://api.groq.com/openai/v1",
        "api_key_env": "GROQ_API_KEY",
        "get_key_url": "https://console.groq.com/",
        "description": "é€Ÿåº¦æå¿«ï¼Œå…è´¹é¢åº¦å……è¶³"
    },
    
    # 2. DeepSeek - æ¨èï¼Œå›½å†…å¯ç”¨
    "deepseek": {
        "name": "DeepSeek Chat",
        "model": "deepseek-chat",
        "base_url": "https://api.deepseek.com/v1",
        "api_key_env": "DEEPSEEK_API_KEY",
        "get_key_url": "https://platform.deepseek.com/",
        "description": "å›½å†…å¯ç”¨ï¼Œå“åº”å¿«"
    },
    
    # 3. ModelScope - ä½ å½“å‰ä½¿ç”¨çš„
    "modelscope": {
        "name": "ModelScope (Qwen)",
        "model": "Qwen/Qwen2.5-72B-Instruct",
        "base_url": "https://api-inference.modelscope.cn/v1/",
        "api_key_env": "LLM_API_KEY",  # ä½¿ç”¨ä½ ç°æœ‰çš„ç¯å¢ƒå˜é‡
        "get_key_url": "https://www.modelscope.cn/",
        "description": "å›½å†…å¯ç”¨ï¼Œä½ å½“å‰ä½¿ç”¨çš„"
    },
    
    # 4. OpenRouter - å¤šä¸ªå…è´¹æ¨¡å‹
    "openrouter": {
        "name": "OpenRouter (Gemini Flash)",
        "model": "google/gemini-flash-1.5",
        "base_url": "https://openrouter.ai/api/v1",
        "api_key_env": "OPENROUTER_API_KEY",
        "get_key_url": "https://openrouter.ai/",
        "description": "èšåˆå¤šä¸ªæ¨¡å‹"
    },
    
    # 5. Together AI
    "together": {
        "name": "Together AI (Llama)",
        "model": "meta-llama/Llama-3-8b-chat-hf",
        "base_url": "https://api.together.xyz/v1",
        "api_key_env": "TOGETHER_API_KEY",
        "get_key_url": "https://www.together.ai/",
        "description": "å¼€æºæ¨¡å‹"
    }
}

def test_model(model_key: str, test_message: str = "ä½ å¥½ï¼Œè¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±"):
    """
    æµ‹è¯•æŒ‡å®šçš„æ¨¡å‹
    
    :param model_key: æ¨¡å‹é…ç½®çš„ keyï¼ˆå¦‚ 'groq', 'deepseek' ç­‰ï¼‰
    :param test_message: æµ‹è¯•æ¶ˆæ¯
    """
    if model_key not in FREE_MODELS_CONFIG:
        print(f"é”™è¯¯ï¼šæœªçŸ¥çš„æ¨¡å‹ key '{model_key}'")
        print(f"å¯ç”¨çš„æ¨¡å‹ï¼š{', '.join(FREE_MODELS_CONFIG.keys())}")
        return False
    
    config = FREE_MODELS_CONFIG[model_key]
    print("=" * 60)
    print(f"æµ‹è¯•æ¨¡å‹ï¼š{config['name']}")
    print(f"æ¨¡å‹ IDï¼š{config['model']}")
    print(f"Base URLï¼š{config['base_url']}")
    print(f"æè¿°ï¼š{config['description']}")
    print("=" * 60)
    
    # è·å– API Key
    api_key = os.getenv(config['api_key_env'])
    if not api_key:
        print(f"\nâŒ é”™è¯¯ï¼šæœªæ‰¾åˆ°ç¯å¢ƒå˜é‡ {config['api_key_env']}")
        print(f"   è¯·è®¾ç½®ç¯å¢ƒå˜é‡æˆ–åœ¨ .env æ–‡ä»¶ä¸­æ·»åŠ ï¼š")
        print(f"   {config['api_key_env']}=your_api_key_here")
        print(f"   è·å– API Keyï¼š{config['get_key_url']}")
        return False
    
    try:
        # åˆ›å»º LLM å®¢æˆ·ç«¯
        llm_client = HelloAgentsLLM(
            model=config['model'],
            apiKey=api_key,
            baseUrl=config['base_url'],
            timeout=60
        )
        
        # æµ‹è¯•æ¶ˆæ¯
        messages = [
            {"role": "user", "content": test_message}
        ]
        
        print(f"\nğŸ“¤ å‘é€æ¶ˆæ¯ï¼š{test_message}")
        print("\nğŸ“¥ å“åº”ï¼š")
        
        # è°ƒç”¨æ¨¡å‹
        response = llm_client.think(messages=messages, temperature=0)
        
        if response:
            print(f"\nâœ… æµ‹è¯•æˆåŠŸï¼")
            print(f"\nå®Œæ•´å“åº”ï¼š\n{response}")
            return True
        else:
            print(f"\nâŒ æµ‹è¯•å¤±è´¥ï¼šæœªæ”¶åˆ°å“åº”")
            return False
            
    except ValueError as e:
        print(f"\nâŒ é…ç½®é”™è¯¯ï¼š{e}")
        return False
    except Exception as e:
        print(f"\nâŒ è°ƒç”¨å¤±è´¥ï¼š{e}")
        print(f"\nå¯èƒ½çš„åŸå› ï¼š")
        print(f"  1. API Key æ— æ•ˆæˆ–è¿‡æœŸ")
        print(f"  2. æ¨¡å‹ ID ä¸æ­£ç¡®")
        print(f"  3. Base URL ä¸æ­£ç¡®")
        print(f"  4. ç½‘ç»œè¿æ¥é—®é¢˜")
        print(f"  5. å…è´¹é¢åº¦å·²ç”¨å®Œ")
        return False

def list_available_models():
    """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„æ¨¡å‹é…ç½®"""
    print("=" * 60)
    print("å¯ç”¨çš„å…è´¹æµ‹è¯•æ¨¡å‹ï¼š")
    print("=" * 60)
    
    for key, config in FREE_MODELS_CONFIG.items():
        api_key = os.getenv(config['api_key_env'])
        status = "âœ… å·²é…ç½®" if api_key else "âŒ æœªé…ç½®"
        
        print(f"\n[{key}] {config['name']}")
        print(f"   æ¨¡å‹ï¼š{config['model']}")
        print(f"   Base URLï¼š{config['base_url']}")
        print(f"   ç¯å¢ƒå˜é‡ï¼š{config['api_key_env']} {status}")
        print(f"   æè¿°ï¼š{config['description']}")
        print(f"   è·å– Keyï¼š{config['get_key_url']}")

def test_all_configured_models(test_message: str = "ä½ å¥½ï¼Œè¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±"):
    """æµ‹è¯•æ‰€æœ‰å·²é…ç½®çš„æ¨¡å‹"""
    print("=" * 60)
    print("æµ‹è¯•æ‰€æœ‰å·²é…ç½®çš„æ¨¡å‹")
    print("=" * 60)
    
    results = {}
    for key in FREE_MODELS_CONFIG.keys():
        config = FREE_MODELS_CONFIG[key]
        api_key = os.getenv(config['api_key_env'])
        
        if api_key:
            print(f"\n\n{'='*60}")
            print(f"æ­£åœ¨æµ‹è¯•ï¼š{config['name']}")
            print(f"{'='*60}")
            success = test_model(key, test_message)
            results[key] = success
        else:
            print(f"\nâ­ï¸  è·³è¿‡ {config['name']}ï¼ˆæœªé…ç½® API Keyï¼‰")
            results[key] = None
    
    # æ±‡æ€»ç»“æœ
    print("\n\n" + "=" * 60)
    print("æµ‹è¯•ç»“æœæ±‡æ€»")
    print("=" * 60)
    for key, result in results.items():
        config = FREE_MODELS_CONFIG[key]
        if result is True:
            print(f"âœ… {config['name']}: æˆåŠŸ")
        elif result is False:
            print(f"âŒ {config['name']}: å¤±è´¥")
        else:
            print(f"â­ï¸  {config['name']}: æœªé…ç½®")

if __name__ == '__main__':
    import sys
    
    if len(sys.argv) > 1:
        # æµ‹è¯•æŒ‡å®šçš„æ¨¡å‹
        model_key = sys.argv[1]
        test_message = sys.argv[2] if len(sys.argv) > 2 else "ä½ å¥½ï¼Œè¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±"
        test_model(model_key, test_message)
    else:
        # äº¤äº’å¼èœå•
        while True:
            print("\n" + "=" * 60)
            print("å…è´¹æ¨¡å‹æµ‹è¯•å·¥å…·")
            print("=" * 60)
            print("\nè¯·é€‰æ‹©æ“ä½œï¼š")
            print("1. åˆ—å‡ºæ‰€æœ‰å¯ç”¨æ¨¡å‹")
            print("2. æµ‹è¯•æŒ‡å®šæ¨¡å‹")
            print("3. æµ‹è¯•æ‰€æœ‰å·²é…ç½®çš„æ¨¡å‹")
            print("4. é€€å‡º")
            
            choice = input("\nè¯·è¾“å…¥é€‰é¡¹ (1-4): ").strip()
            
            if choice == '1':
                list_available_models()
            elif choice == '2':
                list_available_models()
                model_key = input("\nè¯·è¾“å…¥è¦æµ‹è¯•çš„æ¨¡å‹ key: ").strip()
                test_message = input("è¯·è¾“å…¥æµ‹è¯•æ¶ˆæ¯ï¼ˆç›´æ¥å›è½¦ä½¿ç”¨é»˜è®¤ï¼‰: ").strip()
                if not test_message:
                    test_message = "ä½ å¥½ï¼Œè¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±"
                test_model(model_key, test_message)
            elif choice == '3':
                test_message = input("è¯·è¾“å…¥æµ‹è¯•æ¶ˆæ¯ï¼ˆç›´æ¥å›è½¦ä½¿ç”¨é»˜è®¤ï¼‰: ").strip()
                if not test_message:
                    test_message = "ä½ å¥½ï¼Œè¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±"
                test_all_configured_models(test_message)
            elif choice == '4':
                print("å†è§ï¼")
                break
            else:
                print("æ— æ•ˆçš„é€‰é¡¹ï¼Œè¯·é‡æ–°é€‰æ‹©")

